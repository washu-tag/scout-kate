---
# Global settings that apply to all hosts
all:
  vars:
    # Air-gapped deployment configuration
    # Set to true to enable air-gapped deployment mode for Kubernetes clusters
    # without internet access on worker nodes.
    #
    # When enabled (air_gapped: true):
    #   - Helm charts deployed from localhost using remote kubeconfig
    #   - Full Helm functionality retained (rollback, history, hooks)
    #   - Container images pulled through Harbor registry proxy on staging node
    #   - Requires: staging group defined, Harbor deployed, registry mirrors configured
    #   - Requires: k8s API accessible from localhost (port 6443)
    #
    # When disabled (air_gapped: false, default):
    #   - Standard Helm deployment using kubernetes.core.helm module
    #   - Charts pulled directly from public repositories
    #   - Container images pulled directly from public registries
    #   - Works with existing Scout deployments (backward compatible)
    # air_gapped: false  # Default is false; set to true here to override

# The staging group contains the staging node that acts as a data diode
# for air-gapped deployments.
#
# Role: The staging node hosts a Harbor registry that acts as a pull-through
# proxy for container images from public registries (Docker Hub, GitHub Container
# Registry, Quay.io, etc.). It runs a separate k3s cluster from the main cluster.
#
# Requirements for air-gapped deployments (air_gapped: true):
#   1. Staging node must have internet access
#   2. Harbor must be deployed on staging node (playbooks/staging.yaml)
#   3. K3s cluster nodes must have registry mirrors configured to use Harbor
#   4. Kubeconfig for air-gapped cluster must be accessible from localhost
#   5. K8s API port (6443) must be accessible from localhost
#
# Enable air-gapped functionality by setting `air_gapped: true`
# in all vars above.
staging:
  hosts:
    FQDN-staging.edu:
      ansible_host: staging # Host name to use for ssh connection
      ansible_python_interpreter: /usr/bin/python3
      external_url: alt.fqdn.edu # omit to use FQDN-staging.edu
  vars:
    # Staging-specific variables (only needed if air_gapped: true)
    # The staging node runs a separate k3s cluster from the main cluster
    staging_k3s_token: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    harbor_admin_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    harbor_storage_size: 100Gi
    # harbor_expose_type: nodePort

    # Traefik
    tls_cert_path: ''
    tls_key_path: ''

# The server group contains the control plane nodes for the k3s cluster.
server:
  hosts:
    FQDN-leader.edu:
      ansible_connection: local # set if running ansible on this node. if connecting via ssh omit.
      ansible_host: leader # Host name to use for ssh connection; omit if `ansible_connection: local` OR ssh can connect using FQDN
      ansible_python_interpreter: /usr/bin/python3
      k3s_control_node: true
      external_url: alt.fqdn.edu # omit to use FQDN-leader.edu
  vars:
    # Traefik
    tls_cert_path: ''
    tls_key_path: ''

# The workers group contains the worker nodes for the k3s cluster.
workers:
  hosts:
    FQDN-worker-1.edu:
      ansible_connection: local # set if running ansible on this node. if connecting via ssh omit.
      ansible_host: worker-1 # Host name to use for ssh connection; omit if `ansible_connection: local` OR ssh can connect using FQDN
      ansible_python_interpreter: /usr/bin/python3

gpu_workers:
  hosts:
    FQDN-gpu-1.edu:
      ansible_connection: local # set if running ansible on this node. if connecting via ssh omit.
      ansible_host: gpu-1 # Host name to use for ssh connection; omit if `ansible_connection: local` OR ssh can connect using FQDN
      ansible_python_interpreter: /usr/bin/python3
# The agents group contains nodes that run only the k3s agent.
# In this example it only includes the workers and gpu_workers groups.

agents:
  children:
    workers:
    gpu_workers:

# Include in this group any nodes on which MinIO should run.
# Note that if this group contains more than one node, the value of
#  `minio_volumes_per_server` must be greater than 1 or minio will fail to start.
minio_hosts:
  children:
    server:
    workers:

# This group contains all nodes in Scout k3s cluster.
k3s_cluster:
  children:
    server:
    agents:
  vars:
    # Note: Most configuration is now in roles/<role>/defaults/main.yaml
    # or roles/scout_common/defaults/main.yaml (for variables used across roles)
    # Only secrets and production-specific resource overrides are required here,
    # though you can override any role variables you desire.
    #
    # To override versions in group_vars/all/versions.yaml, you need to pass the
    # variable to ansible with -e.
    #
    # Best practice for upgrades: Test version upgrades in your staging
    # environment before applying them to production. For example:
    #   ansible-playbook -e "k3s_version=v1.35.0+k3s1" playbooks/k3s.yaml

    # Namespaces - Scout uses 6 consolidated namespaces by default
    # Core infrastructure (PostgreSQL, Redis, Keycloak, OAuth2-Proxy, Launchpad)
    # scout_core_namespace: scout-core
    #
    # Data layer (MinIO, Hive Metastore)
    # scout_data_namespace: scout-data
    #
    # Extractor & workflow orchestration (Temporal, Cassandra, Elasticsearch, Extractors)
    # scout_extractor_namespace: scout-extractor
    # NOTE: Orchestration services (Temporal, Cassandra, Elasticsearch) cannot be
    # separated into different namespaces - they must share scout_extractor_namespace
    # for proper operation (cross-namespace secret access is not supported).
    #
    # Analytics & user services (Trino, Superset, JupyterHub, Chat)
    # scout_analytics_namespace: scout-analytics
    #
    # Operators (CloudNativePG, MinIO, K8ssandra, ECK, GPU)
    # scout_operators_namespace: scout-operators
    #
    # Monitoring (Prometheus, Loki, Grafana)
    # scout_monitoring_namespace: scout-monitoring
    #
    # Override consolidated namespaces here if needed for your environment
    # Example: scout_core_namespace: my-core-namespace
    # Or override individual service namespaces if needed
    # Example: postgres_cluster_namespace: postgres

    #############################################################################
    ### Storage Configuration                                                 ###
    #############################################################################

    # Custom storage classes for k3s on-prem deployments with multiple disks requiring I/O isolation
    # Leave empty for cloud deployments or single-disk k3s (cluster default will be used)
    onprem_local_path_multidisk_storage_classes: []
    # Example:
    # onprem_local_path_multidisk_storage_classes:
    #   - name: "local-database"
    #     path: "/mnt/disk1/k3s-storage"
    #   - name: "local-objectstorage"
    #     path: "/mnt/disk2/k3s-storage"
    #   - name: "local-monitoring"
    #     path: "/mnt/disk3/k3s-storage"

    # Per-service storage class assignments
    # Default: empty string (use cluster default)
    # Override for multi-disk deployments to assign services to specific storage classes
    # Cloud deployments: leave all empty to use platform default (gp3, pd-ssd, etc.)
    # Example for on-premise multi-disk (uncomment and modify):
    # postgres_storage_class: "local-database"
    # redis_storage_class: "local-database"
    # temporal_storage_class: "local-database"
    # cassandra_storage_class: "local-database"
    # elasticsearch_storage_class: "local-database"
    # minio_storage_class: "local-objectstorage"
    # jupyterhub_storage_class: "local-objectstorage"
    # jupyter_singleuser_storage_class: "local-objectstorage"
    # prometheus_storage_class: "local-monitoring"
    # loki_storage_class: "local-monitoring"
    # grafana_storage_class: "local-monitoring"
    # ollama_storage_class: "local-objectstorage"  # Large model files
    # open_webui_storage_class: "local-database"  # User data and chat history
    # orthanc_storage_class: "local-database"
    # DCM4chee has multiple volumes with different I/O profiles:
    # dcm4chee_wildfly_storage_class: "local-database"  # Application server
    # dcm4chee_storage_storage_class: "local-objectstorage"  # DICOM images (large files)
    # dcm4chee_db_storage_class: "local-database"  # PostgreSQL (high IOPS)
    # dcm4chee_openldap_storage_class: "local-database"  # LDAP data
    # dcm4chee_slapd_storage_class: "local-database"  # LDAP config

    # Storage disk space - Size of persistent volume claims for each service
    postgres_storage_size: 100Gi
    redis_storage_size: 100Gi
    cassandra_storage_size: 300Gi
    elasticsearch_storage_size: 100Gi
    jupyter_hub_storage_size: 15Gi
    jupyter_singleuser_storage_size: 250Gi
    prometheus_storage_size: 100Gi
    loki_storage_size: 100Gi
    grafana_storage_size: 50Gi
    minio_storage_size: 750Gi

    # HL7 extractor input directory (not managed by Kubernetes persistent volumes)
    extractor_data_dir: /ceph/input/data

    #############################################################################
    ### Service-specific secrets and resources                                ###
    #############################################################################

    #---------------------------------------------------------------------------
    # K3s
    #---------------------------------------------------------------------------
    k3s_token: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    # CoreDNS custom DNS configuration (see docs/source/technical/inventory.md)
    # When air_gapped: true, CoreDNS automatically gets deny-all + cluster.local blocks
    #
    # Domains to forward to /etc/resolv.conf (e.g., Tailscale, VPN):
    # coredns_forward_domains:
    #   - ts.net
    #
    # Arbitrary CoreDNS server blocks (works with or without air_gapped):
    # coredns_extra_server_blocks:
    #   scout-override: !unsafe |
    #     app.example.com:53 {
    #       template IN A app.example.com {
    #         answer "{{ .Name }} 60 IN A 198.51.100.10"
    #       }
    #     }

    #---------------------------------------------------------------------------
    # OAuth2 Proxy
    #---------------------------------------------------------------------------
    oauth2_proxy_cookie_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    oauth2_proxy_redis_password: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    #---------------------------------------------------------------------------
    # Keycloak
    #---------------------------------------------------------------------------
    # User-facing name for OAuth provider shown in login interfaces
    oauth_provider_name: WashU Key # or 'Keycloak', 'GitHub', etc.
    # Keycloak Postgres
    keycloak_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    # Keycloak admin console
    keycloak_bootstrap_admin_user: admin
    keycloak_bootstrap_admin_password: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    # IDP configuration (pick at least one)
    keycloak_default_provider: github # 'github' or 'microsoft'
    keycloak_gh_client_id: 'your-github-client'
    keycloak_gh_client_secret: 'your-github-secret'
    keycloak_microsoft_client_id: 'your-microsoft-client'
    keycloak_microsoft_client_secret: 'your-microsoft-secret'
    keycloak_microsoft_tenant_id: 'your-microsoft-tenant-id'
    # Client secrets for Scout services
    keycloak_oauth2_proxy_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_superset_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_jupyterhub_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_grafana_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_temporal_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_minio_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_launchpad_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    keycloak_open_webui_client_secret: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    # SMTP configuration (optional)
    keycloak_smtp_host: ''
    keycloak_smtp_port: ''
    keycloak_smtp_from: ''
    keycloak_smtp_from_display_name: ''
    keycloak_smtp_auth: ''
    keycloak_smtp_ssl: ''
    keycloak_smtp_starttls: ''

    #---------------------------------------------------------------------------
    # Launchpad
    #---------------------------------------------------------------------------
    launchpad_nextauth_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)

    #---------------------------------------------------------------------------
    # PostgreSQL
    #---------------------------------------------------------------------------
    postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    postgres_superuser_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    # Production resource overrides (defaults in role are for dev)
    postgres_resources:
      requests:
        cpu: 4
        memory: 64Gi
      limits:
        cpu: 6
        memory: 96Gi
    postgres_parameters: # Production tuning (defaults in role are for dev)
      max_connections: '120'
      shared_buffers: '16GB'
      effective_cache_size: '48GB'
      maintenance_work_mem: '2GB'
      checkpoint_completion_target: '0.9'
      wal_buffers: '16MB'
      default_statistics_target: '500'
      random_page_cost: '4'
      effective_io_concurrency: '1'
      work_mem: '2GB'
      huge_pages: 'try'
      min_wal_size: '4GB'
      max_wal_size: '16GB'
      max_worker_processes: '4'
      max_parallel_workers_per_gather: '2'
      max_parallel_workers: '4'
      max_parallel_maintenance_workers: '2'

    #---------------------------------------------------------------------------
    # Cassandra
    #---------------------------------------------------------------------------
    cassandra_init_heap: 6G
    cassandra_max_heap: 12G
    # Memory computed from max_heap (requests = 1x = 12Gi, limits = 2x = 24Gi)
    # Override CPU if needed (defaults: 250m request, 2 limit):
    cassandra_cpu_request: 2
    cassandra_cpu_limit: 4

    #---------------------------------------------------------------------------
    # Elasticsearch
    #---------------------------------------------------------------------------
    elasticsearch_max_heap: 3G
    # Memory computed from heap_size (requests = 2x = 6Gi, limits = 4x = 12Gi)
    # Note: Heap should be ≤ 50% of pod memory, and ≤ 26GB for compressed OOPs
    # Override CPU if needed (defaults: 250m request, 2 limit):
    elasticsearch_cpu_request: 1
    elasticsearch_cpu_limit: 3

    #---------------------------------------------------------------------------
    # MinIO (Object Storage)
    #---------------------------------------------------------------------------
    # Ensure passwords meet complexity requirements (must be >=8 characters)
    minio_volumes_per_server: 2 # See comment with `minio_hosts`
    s3_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    s3_lake_reader_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    s3_lake_writer_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    minio_resources:
      requests:
        cpu: 2
        memory: 8Gi
      limits:
        cpu: 4
        memory: 8Gi

    #---------------------------------------------------------------------------
    # Prometheus
    #---------------------------------------------------------------------------
    prometheus_resources:
      requests:
        cpu: 2
        memory: 8Gi
      limits:
        cpu: 4
        memory: 8Gi

    #---------------------------------------------------------------------------
    # Loki
    #---------------------------------------------------------------------------
    s3_loki_writer_secret: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    loki_resources:
      requests:
        cpu: 2
        memory: 8Gi
      limits:
        cpu: 4
        memory: 8Gi
    # Memcached cache configuration (optional - has dev-friendly defaults)
    # Loki uses memcached for caching log chunks and query results
    # Values are in MB. Pod memory is computed as allocatedMemory * 1.2
    # Role defaults: 512MB chunks, 256MB results (adequate for most deployments)
    # Upstream defaults: 8192MB chunks, 1024MB results (overkill for most)
    # Uncomment to override for large-scale production deployments:
    # loki_chunks_cache_allocated_memory: 1024  # MB
    # loki_results_cache_allocated_memory: 512  # MB

    #---------------------------------------------------------------------------
    # Grafana
    #---------------------------------------------------------------------------
    grafana_alert_contact_point: slack # email or slack
    # Slack configuration
    slack_token: $(echo $SLACK_TOKEN | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    slack_channel_id: $(echo $SLACK_CHANNEL | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    # SMTP configuration
    grafana_smtp_host: '' # Include the port in the value
    grafana_smtp_user: $(echo $SMTP_USER | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    grafana_smtp_password: $(echo $SMTP_PASSWORD | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    grafana_smtp_from_address: ''
    grafana_smtp_from_name: 'Scout'
    grafana_smtp_skip_verify: false
    grafana_email_recipients: ['']
    # Resources
    grafana_resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        cpu: 2
        memory: 4Gi

    #---------------------------------------------------------------------------
    # Jupyter
    #---------------------------------------------------------------------------
    jupyter_metrics_api_token: $(openssl rand -hex 32  | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    jupyter_hub_resources:
      requests:
        cpu: 500m
        memory: 1G
      limits:
        cpu: 2
        memory: 2G
    # Example: Add GPU profile alongside default CPU profile
    # The default includes "CPU Only" profile with Small/Medium/Large options
    # jupyter_profiles:
    #   - "{{ jupyter_cpu_profile }}"  # Include default CPU profile
    #   - display_name: "GPU"
    #     slug: "gpu"
    #     description: "GPU environment for ML/AI workloads"
    #     profile_options:
    #       resource_allocation:
    #         display_name: "Resource Size"
    #         choices:
    #           medium:
    #             display_name: "Medium (8 CPU, 32Gi RAM, 1 GPU)"
    #             default: true
    #             kubespawner_override:
    #               cpu_guarantee: 4
    #               cpu_limit: 8
    #               mem_guarantee: '16G'
    #               mem_limit: '32G'
    #               environment:
    #                 SPARK_DRIVER_MEMORY: "24g"
    #                 SPARK_EXECUTOR_MEMORY: "24g"
    #               extra_resource_guarantees:
    #                 nvidia.com/gpu: '1'
    #               extra_resource_limits:
    #                 nvidia.com/gpu: '1'
    #           large:
    #             display_name: "Large (16 CPU, 64Gi RAM, 1 GPU)"
    #             kubespawner_override:
    #               cpu_guarantee: 8
    #               cpu_limit: 16
    #               mem_guarantee: '32G'
    #               mem_limit: '64G'
    #               environment:
    #                 SPARK_DRIVER_MEMORY: "48g"
    #                 SPARK_EXECUTOR_MEMORY: "48g"
    #               extra_resource_guarantees:
    #                 nvidia.com/gpu: '1'
    #               extra_resource_limits:
    #                 nvidia.com/gpu: '1'

    # JupyterLab Extension Manager configuration
    # Controls whether users can install/manage JupyterLab extensions
    # jupyter_extension_manager_mode: 'disabled'  # Options: 'disabled' (Scout default), 'readonly', 'enabled'
    #   'disabled' - Hide Extension Manager UI completely (Scout default, recommended for air-gapped/production)
    #   'readonly' - Show installed extensions, allow enable/disable, but no installation
    #   'enabled'  - Full extension management (users can install from PyPI)

    # JupyterHub automatic shutdown settings
    # Servers automatically stop after jupyter_cull_max_age seconds
    # jupyter_cull_enabled: true                 # Enable automatic shutdown
    # jupyter_cull_every: 600                    # Check every 10 minutes
    # jupyter_cull_max_age: 172800               # 2 days (48 hours)
    # jupyter_cull_remove_named_servers: true    # Remove all server types
    # jupyter_cull_concurrency: 10               # Parallel culling operations

    #---------------------------------------------------------------------------
    # Temporal
    #---------------------------------------------------------------------------
    temporal_resources:
      requests:
        cpu: 1
        memory: 4Gi
      limits:
        cpu: 2
        memory: 8Gi

    #---------------------------------------------------------------------------
    # Superset
    #---------------------------------------------------------------------------
    superset_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    superset_secret: $(openssl rand -base64 42 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    superset_redis_password: $(openssl rand -hex 16 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    superset_resources:
      requests:
        cpu: 1
        memory: 4Gi
      limits:
        cpu: 2
        memory: 8Gi

    #---------------------------------------------------------------------------
    # Hive Metastore
    #---------------------------------------------------------------------------
    hive_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    hive_readonly_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    hive_resources:
      requests:
        cpu: 1
        memory: 4Gi
      limits:
        cpu: 2
        memory: 4Gi

    #---------------------------------------------------------------------------
    # Trino
    #---------------------------------------------------------------------------
    trino_worker_count: 2 # Number of worker replicas
    trino_worker_max_heap: 12G
    trino_coordinator_max_heap: 6G
    # Override CPU if needed (defaults: 250m request, 2/1 limit for worker/coordinator):
    trino_worker_cpu_request: 2
    trino_worker_cpu_limit: 6
    trino_coordinator_cpu_request: 1
    trino_coordinator_cpu_limit: 3
    # Override query memory allocation if needed (default: 0.3 = 30% of heap per Trino docs)
    # trino_per_node_query_memory_fraction: 0.3
    # MCP Trino server resources (used by Open WebUI for natural language SQL queries)
    mcp_trino_resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 1
        memory: 2Gi

    #---------------------------------------------------------------------------
    # Extractor
    #---------------------------------------------------------------------------
    hl7log_extractor_resources:
      requests:
        cpu: 2
        memory: 4Gi
      limits:
        cpu: 4
        memory: 75Gi
    hl7log_extractor_jvm_heap_max_ram_percentage: 80
    hl7_transformer_spark_memory: 16G
    # Memory computed from spark_memory (requests = 1x = 16Gi, limits = 2x = 32Gi)
    # Override CPU if needed (defaults: 250m request, 4 limit):
    hl7_transformer_cpu_request: 2
    hl7_transformer_cpu_limit: 4

    #---------------------------------------------------------------------------
    # Chatbot (Open WebUI)
    #---------------------------------------------------------------------------
    # Uncomment the following line to enable the Chat service
    # enable_chat: true
    open_webui_redis_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    open_webui_postgres_password: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    open_webui_secret_key: $(openssl rand -hex 32 | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    ollama_resources:
      requests:
        cpu: 4
        memory: 32Gi
      limits:
        cpu: 16
        memory: 64Gi
    open_webui_resources:
      requests:
        cpu: 1
        memory: 2Gi
      limits:
        cpu: 4
        memory: 4Gi

    #---------------------------------------------------------------------------
    # Playbooks (Voilà)
    #---------------------------------------------------------------------------
    # Uncomment the following line to enable interactive notebook playbooks
    # enable_playbooks: true
    # voila_replicas: 1
    # voila_resources:
    #   requests:
    #     cpu: 500m
    #     memory: 2Gi
    #   limits:
    #     cpu: 2
    #     memory: 8Gi

# This group contains all nodes that are remote relative to the node running Ansible
remotes:
  children:
    staging:
    k3s_cluster:
  vars:
    # SSH connection and privilege escalation
    # There are many other params you could set here to customize your situation.
    # See https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html#connecting-to-hosts-behavioral-inventory-parameters
    ansible_user: '<ssh username>'
    ansible_become_method: sudo
    ansible_become_flags: '-i'
    ansible_become_user: root
    ansible_become_password: $(echo $ANSIBLE_BECOME_PASSWORD | ansible-vault encrypt_string --vault-password-file vault/pwd.sh)
    ansible_become: true
    # ansible_remote_tmp: /tmp/.ansible-{{ ansible_user }} # May be needed depending on home directory permissions

    #---------------------------------------------------------------------------
    # Kubeconfig
    #---------------------------------------------------------------------------
    # K3s kubeconfig path, modify if not using K3s
    # kubeconfig_yaml: /etc/rancher/k3s/k3s.yaml
    kubeconfig_group: '<name of the linux group that should be able to run kubectl>'
